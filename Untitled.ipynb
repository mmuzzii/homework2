{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date'])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#将json文件转换为csv\n",
    "json_file_path='yelp_academic_dataset_review.json'\n",
    "csv_file_path='yelp_academic_dataset_review.csv'\n",
    "\n",
    "#打开business.json文件,取出第一行列名\n",
    "with open(json_file_path,'r',encoding='utf-8') as fin:\n",
    "    for line in fin:\n",
    "        line_contents = json.loads(line)\n",
    "        headers=line_contents.keys()\n",
    "        break\n",
    "    print(headers)\n",
    "    \n",
    "#将json读成字典,其键值写入business.csv的列名,再将json文件中的values逐行写入business.csv文件\n",
    "with open(csv_file_path, 'w', newline='',encoding='utf-8') as fout:\n",
    "    writer=csv.DictWriter(fout, headers)\n",
    "    writer.writeheader()\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as fin:\n",
    "        for line in fin:\n",
    "            line_contents = json.loads(line)\n",
    "            #if 'Phoenix' in line_contents.values():\n",
    "            writer.writerow(line_contents)\n",
    "            \n",
    " # 删除state','postal_code','is_open','attributes'列,并保存\n",
    " # 可以根据需要选择，这里是针对review文件的一些列。\n",
    "df_bus=pd.read_csv(csv_file_path)\n",
    "df_reduced=df_bus.drop(['compliment_hot','compliment_more','compliment_profile'],axis=1)\n",
    "df_cleaned=df_reduced.dropna()\n",
    "df_cleaned.to_csv(csv_file_path,index=False)\n",
    "df_bus=pd.read_csv(csv_file_path)\n",
    "\n",
    "df_bus.to_csv(csv_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id\n",
      "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw\n",
      "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ\n",
      "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A\n",
      "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA\n",
      "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 使用 usecols 参数指定需要读取的列\n",
    "cols_to_use = ['review_id', 'user_id', 'business_id']\n",
    "df = pd.read_csv('yelp_academic_dataset_review.csv', usecols=cols_to_use)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user_id                                         businesses\n",
      "0  ---1lKK3aKOuomHnwAkAow                           [f19eLfhXqR47Ct8Hz2y_pA]\n",
      "1  ---2PmXbF47D870stH1jqA  [hKameFsaXh9g8WQbv593UA, hKameFsaXh9g8WQbv593U...\n",
      "2  ---UgP94gokyCDuB5zUssA  [hKr-RKMVpj3gRkSWcjg3Zw, GBTPC53ZrG1ZBY3DT8Mbc...\n",
      "3  ---fa6ZK37T9NjkGKI4oSg                           [fGQfNfP7squRJjFKk2NWkw]\n",
      "4  ---r61b7EpVPkb4UVme5tA  [fGYnHzFr1z2kv7bPRW6VMA, 5UN1B7XqZohGuULLNlWL1...\n",
      "user_id       False\n",
      "businesses    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 按 'user_id' 对数据进行分组，并将每个用户的 'business_id' 聚合成一个列表\n",
    "user_business_df = df.groupby('user_id')['business_id'].agg(list).reset_index()\n",
    "\n",
    "# 重命名列，使其更具描述性\n",
    "user_business_df.columns = ['user_id', 'businesses']\n",
    "\n",
    "# 显示结果的前几行\n",
    "print(user_business_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                                         categories\n",
      "0  Pns2l4eNsfO8kk83dixA6A  Doctors, Traditional Chinese Medicine, Naturop...\n",
      "1  mpf3x-BjTdTEA3yCZrAYPw  Shipping Centers, Local Services, Notaries, Ma...\n",
      "2  tUFrWirKiKi_TAnsVWINQQ  Department Stores, Shopping, Fashion, Home & G...\n",
      "3  MTSW4McQd7CbVtyjqoe9mw  Restaurants, Food, Bubble Tea, Coffee & Tea, B...\n",
      "4  mWMc6_wTdE0EUBKIGXDVfA                          Brewpubs, Breweries, Food\n",
      "business_id    False\n",
      "categories      True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "def read_json(file_name): ## helper method to read json files more efficiently \n",
    "    df = pd.DataFrame()\n",
    "    chunk_size = 100000\n",
    "    for chunk in pd.read_json(file_name, chunksize=chunk_size, lines=True):\n",
    "        chunk = chunk[['business_id', 'categories']]\n",
    "        df = pd.concat([df, chunk])\n",
    "    return df\n",
    "business_df = read_json('yelp_academic_dataset_business.json')\n",
    "print(business_df.head())\n",
    "\n",
    "has_none = business_df.isnull().any()\n",
    "print(has_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user_id                                         businesses  \\\n",
      "0  ---1lKK3aKOuomHnwAkAow                           [f19eLfhXqR47Ct8Hz2y_pA]   \n",
      "1  ---2PmXbF47D870stH1jqA  [hKameFsaXh9g8WQbv593UA, hKameFsaXh9g8WQbv593U...   \n",
      "2  ---UgP94gokyCDuB5zUssA  [hKr-RKMVpj3gRkSWcjg3Zw, GBTPC53ZrG1ZBY3DT8Mbc...   \n",
      "3  ---fa6ZK37T9NjkGKI4oSg                           [fGQfNfP7squRJjFKk2NWkw]   \n",
      "4  ---r61b7EpVPkb4UVme5tA  [fGYnHzFr1z2kv7bPRW6VMA, 5UN1B7XqZohGuULLNlWL1...   \n",
      "\n",
      "                                          categories  \n",
      "0  [Doctors, Active Life, Float Spa, Health & Med...  \n",
      "1  [Seafood, Steakhouses, Salad, Comfort Food, Re...  \n",
      "2  [American (New), Restaurants, Mexican, German,...  \n",
      "3  [Home & Garden, Home Decor, Shopping, Furnitur...  \n",
      "4  [Pizza, Event Planning & Services, Italian, Ca...  \n"
     ]
    }
   ],
   "source": [
    "# 将用户和商家列表转换成长格式\n",
    "'''rows = []\n",
    "for i, row in user_business_df.iterrows():\n",
    "    for business in row['businesses']:\n",
    "        rows.append({'user_id': row['user_id'], 'businesses': business})\n",
    "\n",
    "user_business_long_df = pd.DataFrame(rows)\n",
    "print(user_business_long_df.head())'''\n",
    "\n",
    "# 清除 categories 为空的行\n",
    "business_df = business_df[business_df['categories'].notnull() & (business_df['categories'] != '')]\n",
    "\n",
    "# 创建商家ID到类别的映射字典，此时不包括任何空的 categories\n",
    "category_map = business_df.set_index('business_id')['categories'].to_dict()\n",
    "\n",
    "# 替换用户交互的每个商家ID为对应的类别\n",
    "user_business_df['categories'] = user_business_df['businesses'].apply(\n",
    "    lambda x: [category_map[biz] for biz in x if biz in category_map]\n",
    ")\n",
    "user_business_df['categories'] = user_business_df['businesses'].apply(\n",
    "    lambda x: [category_map[biz] for biz in x if biz in category_map] if any(biz in category_map for biz in x) else ['No Category']\n",
    ")\n",
    "\n",
    "print(user_business_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3D Printing, Local Services, Hobby Shops, Shopping  \\\n",
      "0                                                  0    \n",
      "1                                                  0    \n",
      "2                                                  0    \n",
      "3                                                  0    \n",
      "4                                                  0    \n",
      "\n",
      "   ATV Rentals/Tours, Hotels & Travel, Tours, Fishing, Active Life, Boating  \\\n",
      "0                                                  0                          \n",
      "1                                                  0                          \n",
      "2                                                  0                          \n",
      "3                                                  0                          \n",
      "4                                                  0                          \n",
      "\n",
      "   ATV Rentals/Tours, Motorcycle Repair, Automotive, Active Life  \\\n",
      "0                                                  0               \n",
      "1                                                  0               \n",
      "2                                                  0               \n",
      "3                                                  0               \n",
      "4                                                  0               \n",
      "\n",
      "   Acai Bowls, American (New), Restaurants, Fast Food, Breakfast & Brunch, Food, Vegetarian  \\\n",
      "0                                                  0                                          \n",
      "1                                                  0                                          \n",
      "2                                                  0                                          \n",
      "3                                                  0                                          \n",
      "4                                                  0                                          \n",
      "\n",
      "   Acai Bowls, Asian Fusion, Food, Restaurants, Bars, Event Planning & Services, Breakfast & Brunch, Tapas/Small Plates, Chinese, Sandwiches, Caterers, Cocktail Bars, Nightlife  \\\n",
      "0                                                  0                                                                                                                               \n",
      "1                                                  0                                                                                                                               \n",
      "2                                                  0                                                                                                                               \n",
      "3                                                  0                                                                                                                               \n",
      "4                                                  0                                                                                                                               \n",
      "\n",
      "   Acai Bowls, Breakfast & Brunch, Coffee & Tea, Restaurants, Food, Juice Bars & Smoothies  \\\n",
      "0                                                  0                                         \n",
      "1                                                  0                                         \n",
      "2                                                  0                                         \n",
      "3                                                  0                                         \n",
      "4                                                  0                                         \n",
      "\n",
      "   Acai Bowls, Coffee & Tea, Food, Juice Bars & Smoothies, Restaurants  \\\n",
      "0                                                  0                     \n",
      "1                                                  0                     \n",
      "2                                                  0                     \n",
      "3                                                  0                     \n",
      "4                                                  0                     \n",
      "\n",
      "   Acai Bowls, Coffee & Tea, Juice Bars & Smoothies, Food, Restaurants  \\\n",
      "0                                                  0                     \n",
      "1                                                  0                     \n",
      "2                                                  0                     \n",
      "3                                                  0                     \n",
      "4                                                  0                     \n",
      "\n",
      "   Acai Bowls, Food  \\\n",
      "0                 0   \n",
      "1                 0   \n",
      "2                 0   \n",
      "3                 0   \n",
      "4                 0   \n",
      "\n",
      "   Acai Bowls, Food Delivery Services, Salad, Poke, Juice Bars & Smoothies, American (Traditional), Food, American (New), Restaurants  \\\n",
      "0                                                  0                                                                                    \n",
      "1                                                  0                                                                                    \n",
      "2                                                  0                                                                                    \n",
      "3                                                  0                                                                                    \n",
      "4                                                  0                                                                                    \n",
      "\n",
      "   ...  Zoos, Active Life, Arts & Entertainment  \\\n",
      "0  ...                                        0   \n",
      "1  ...                                        0   \n",
      "2  ...                                        0   \n",
      "3  ...                                        0   \n",
      "4  ...                                        0   \n",
      "\n",
      "   Zoos, Active Life, Community Service/Non-Profit, Local Services  \\\n",
      "0                                                  0                 \n",
      "1                                                  0                 \n",
      "2                                                  0                 \n",
      "3                                                  0                 \n",
      "4                                                  0                 \n",
      "\n",
      "   Zoos, Active Life, Food, Farmers Market  \\\n",
      "0                                        0   \n",
      "1                                        0   \n",
      "2                                        0   \n",
      "3                                        0   \n",
      "4                                        0   \n",
      "\n",
      "   Zoos, Active Life, Kids Activities, Petting Zoos  \\\n",
      "0                                                 0   \n",
      "1                                                 0   \n",
      "2                                                 0   \n",
      "3                                                 0   \n",
      "4                                                 0   \n",
      "\n",
      "   Zoos, Arts & Entertainment, Active Life, Festivals  \\\n",
      "0                                                  0    \n",
      "1                                                  0    \n",
      "2                                                  0    \n",
      "3                                                  0    \n",
      "4                                                  0    \n",
      "\n",
      "   Zoos, Arts & Entertainment, Performing Arts, Active Life, Parks, Skating Rinks, Tennis, Museums, Public Services & Government, Golf, Landmarks & Historical Buildings  \\\n",
      "0                                                  0                                                                                                                       \n",
      "1                                                  0                                                                                                                       \n",
      "2                                                  0                                                                                                                       \n",
      "3                                                  0                                                                                                                       \n",
      "4                                                  0                                                                                                                       \n",
      "\n",
      "   Zoos, Botanical Gardens, Children's Museums, Active Life, Arts & Entertainment, Petting Zoos, Museums  \\\n",
      "0                                                  0                                                       \n",
      "1                                                  0                                                       \n",
      "2                                                  0                                                       \n",
      "3                                                  0                                                       \n",
      "4                                                  0                                                       \n",
      "\n",
      "   Zoos, Event Planning & Services, Venues & Event Spaces, Active Life  \\\n",
      "0                                                  0                     \n",
      "1                                                  0                     \n",
      "2                                                  0                     \n",
      "3                                                  0                     \n",
      "4                                                  0                     \n",
      "\n",
      "   Zoos, Hotels & Travel, Event Planning & Services, Tours, Active Life, Venues & Event Spaces, Historical Tours  \\\n",
      "0                                                  0                                                               \n",
      "1                                                  0                                                               \n",
      "2                                                  0                                                               \n",
      "3                                                  0                                                               \n",
      "4                                                  0                                                               \n",
      "\n",
      "   Zoos, Tours, Arts & Entertainment, Hotels & Travel, Active Life  \n",
      "0                                                  0                \n",
      "1                                                  0                \n",
      "2                                                  0                \n",
      "3                                                  0                \n",
      "4                                                  0                \n",
      "\n",
      "[5 rows x 83161 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "dataset = user_business_df['categories'].tolist()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# 计算每个项目的频率\n",
    "item_frequency = defaultdict(int)\n",
    "for transaction in dataset:\n",
    "    for item in transaction:\n",
    "        item_frequency[item] += 1\n",
    "\n",
    "# 过滤掉低频项\n",
    "min_frequency = 5  # 可以调整这个阈值\n",
    "filtered_dataset = [[item for item in transaction if item_frequency[item] >= min_frequency] for transaction in dataset]\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset, sparse=True)\n",
    "df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    support                      itemsets\n",
      "0  0.012843  (Beauty & Spas, Nail Salons)\n",
      "1  0.010011        (Chinese, Restaurants)\n",
      "2  0.011695        (Italian, Restaurants)\n",
      "3  0.023103        (Mexican, Restaurants)\n",
      "4  0.010869  (Nail Salons, Beauty & Spas)\n",
      "5  0.012907          (Pizza, Restaurants)\n",
      "6  0.010865        (Restaurants, Chinese)\n",
      "7  0.011939        (Restaurants, Italian)\n",
      "8  0.022963        (Restaurants, Mexican)\n",
      "9  0.014744          (Restaurants, Pizza)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# 使用 Apriori 算法找到频繁项集，含义为商户共同出现的模式\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import urllib\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Temporary folder for data we need during execution of this notebook (we'll clean up\n",
    "# at the end, we promise)\n",
    "temp_dir = os.path.join(tempfile.gettempdir(), 'mind')\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# The dataset is split into training and validation set, each with a large and small version.\n",
    "# The format of the four files are the same.\n",
    "# For demonstration purpose, we will use small version validation set only.\n",
    "base_url = 'https://mind201910small.blob.core.windows.net/release'\n",
    "training_small_url = f'{base_url}/MINDsmall_train.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url,\n",
    "                 destination_filename=None,\n",
    "                 progress_updater=None,\n",
    "                 force_download=False,\n",
    "                 verbose=True):\n",
    "    \"\"\"\n",
    "    Download a URL to a temporary file\n",
    "    \"\"\"\n",
    "    if not verbose:\n",
    "        progress_updater = None\n",
    "    # This is not intended to guarantee uniqueness, we just know it happens to guarantee\n",
    "    # uniqueness for this application.\n",
    "    if destination_filename is None:\n",
    "        url_as_filename = url.replace('://', '_').replace('/', '_')\n",
    "        destination_filename = \\\n",
    "            os.path.join(temp_dir,url_as_filename)\n",
    "    if (not force_download) and (os.path.isfile(destination_filename)):\n",
    "        if verbose:\n",
    "            print('Bypassing download of already-downloaded file {}'.format(\n",
    "                os.path.basename(url)))\n",
    "        return destination_filename\n",
    "    if verbose:\n",
    "        print('Downloading file {} to {}'.format(os.path.basename(url),\n",
    "                                                 destination_filename),\n",
    "              end='')\n",
    "    urllib.request.urlretrieve(url, destination_filename, progress_updater)\n",
    "    assert (os.path.isfile(destination_filename))\n",
    "    nBytes = os.path.getsize(destination_filename)\n",
    "    if verbose:\n",
    "        print('...done, {} bytes.'.format(nBytes))\n",
    "    return destination_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file MINDsmall_train.zip to C:\\Users\\Mayn\\AppData\\Local\\Temp\\mind\\https_mind201910small.blob.core.windows.net_release_MINDsmall_train.zip...done, 52952752 bytes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['behaviors.tsv',\n",
       " 'entity_embedding.vec',\n",
       " 'https_mind201910small.blob.core.windows.net_release_MINDsmall_train.zip',\n",
       " 'news.tsv',\n",
       " 'relation_embedding.vec']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For demonstration purpose, we will use small version validation set only.\n",
    "# This file is about 30MB.\n",
    "zip_path = download_url(training_small_url, verbose=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "os.listdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   impression_id user_id                   time  \\\n",
      "0              1  U13740  11/11/2019 9:05:58 AM   \n",
      "1              2  U91836  11/12/2019 6:11:30 PM   \n",
      "2              3  U73700  11/14/2019 7:01:48 AM   \n",
      "3              4  U34670  11/11/2019 5:28:05 AM   \n",
      "4              5   U8125  11/12/2019 4:11:21 PM   \n",
      "\n",
      "                                             history  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         impressions  \n",
      "0                                  N55689-1 N35729-0  \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...  \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...  \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0  \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...  \n"
     ]
    }
   ],
   "source": [
    "behaviors_path = os.path.join(temp_dir, 'behaviors.tsv')\n",
    "behavior_df=pd.read_table(\n",
    "    behaviors_path,\n",
    "    header=None,\n",
    "    names=['impression_id', 'user_id', 'time', 'history', 'impressions'])\n",
    "print(behavior_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id                     clicked_news\n",
      "0    U100                          [N7800]\n",
      "1   U1000  [N29739, N7670, N58656, N53875]\n",
      "2  U10001          [N1031, N10833, N35937]\n",
      "3  U10003         [N18708, N57090, N55689]\n",
      "4  U10008                         [N15405]\n"
     ]
    }
   ],
   "source": [
    "# 从behavior中提取每个用户点击过的新闻\n",
    "\n",
    "def extract_clicked_news(impressions):\n",
    "    # 分割字符串，创建新闻编号和点击状态的元组列表\n",
    "    news_click_tuples = [news.split('-') for news in impressions.split()]\n",
    "    # 过滤出点击状态为'1'的新闻编号\n",
    "    clicked_news = [news_id for news_id, click_status in news_click_tuples if click_status == '1']\n",
    "    return clicked_news\n",
    "\n",
    "# 过滤出非空新闻编号的行\n",
    "#behavior_df = behavior_df[behavior_df['clicked_news'].notnull()\n",
    "\n",
    "# 应用这个函数到每一行的impressions列\n",
    "behavior_df['clicked_news'] = behavior_df['impressions'].apply(extract_clicked_news)\n",
    "\n",
    "# 使用groupby将每个用户点击的新闻编号合并成一个列表\n",
    "user_clicked_news = behavior_df.groupby('user_id')['clicked_news'].agg(lambda x: [item for sublist in x for item in sublist])\n",
    "\n",
    "# 将结果转换为DataFrame\n",
    "clicked_df = user_clicked_news.reset_index()\n",
    "\n",
    "# 使用 boolean indexing 移除空列表的行\n",
    "clicked_df = clicked_df[clicked_df['clicked_news'].map(bool)]\n",
    "\n",
    "# 重置索引，因为移除行后索引可能会不连续\n",
    "clicked_df = clicked_df.reset_index(drop=True)\n",
    "\n",
    "# 打印结果\n",
    "print(clicked_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id   category      subcategory  \\\n",
      "0  N55528  lifestyle  lifestyleroyals   \n",
      "1  N19639     health       weightloss   \n",
      "2  N61837       news        newsworld   \n",
      "3  N53526     health           voices   \n",
      "4  N38324     health          medical   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1                      50 Worst Habits For Belly Fat   \n",
      "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
      "4  How to Get Rid of Skin Tags, According to a De...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  These seemingly harmless habits are holding yo...   \n",
      "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "3  I felt like I was a fraud, and being an NBA wi...   \n",
      "4  They seem harmless, but there's a very good re...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
      "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
      "\n",
      "                                      title_entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
      "\n",
      "                                   abstract_entities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "3  [{\"Label\": \"National Basketball Association\", ...  \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  \n"
     ]
    }
   ],
   "source": [
    "news_path = os.path.join(temp_dir, 'news.tsv')\n",
    "news_df=pd.read_table(news_path,\n",
    "              header=None,\n",
    "              names=[\n",
    "                  'id', 'category', 'subcategory', 'title', 'abstract', 'url',\n",
    "                  'title_entities', 'abstract_entities'\n",
    "              ])\n",
    "print(news_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id                                       clicked_news\n",
      "0    U100                                        [newscrime]\n",
      "1   U1000  [newsworld, tipsandtricks, movies-gallery, new...\n",
      "2  U10001      [autosownership, travelarticle, football_nfl]\n",
      "3  U10003                    [fitness, awards, football_nfl]\n",
      "4  U10008                                [weathertopstories]\n"
     ]
    }
   ],
   "source": [
    "# 将news_id替换为它们的子类别\n",
    "\n",
    "# 创建一个从新闻ID到subcategory的映射\n",
    "id_to_subcategory = pd.Series(news_df['subcategory'].values, index=news_df['id']).to_dict()\n",
    "\n",
    "# 定义一个函数，它将 clicked_news_sequence 中的 news_id 替换为 subcategory\n",
    "def replace_id_with_subcategory(news_sequence):\n",
    "    # 使用映射替换 news_id，如果 news_id 在映射中找不到则保留原始值\n",
    "    return [id_to_subcategory.get(news_id, news_id) for news_id in news_sequence]\n",
    "\n",
    "# 应用这个函数到 clicked_df 的每一行\n",
    "clicked_df['clicked_news'] = clicked_df['clicked_news'].apply(replace_id_with_subcategory)\n",
    "\n",
    "# 打印结果\n",
    "print(clicked_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support                                           itemsets\n",
      "0    0.03486                                          (animals)\n",
      "1    0.01370                                    (autosclassics)\n",
      "2    0.03210                                 (autosenthusiasts)\n",
      "3    0.01324                                 (autosmotorcycles)\n",
      "4    0.03532                                        (autosnews)\n",
      "..       ...                                                ...\n",
      "399  0.01338       (football_nfl, newsus, newscrime, newsworld)\n",
      "400  0.01034  (newsus, music-celebrity, lifestylebuzz, newsc...\n",
      "401  0.01102      (newsus, lifestylebuzz, newscrime, newsworld)\n",
      "402  0.01184    (music-celebrity, newsus, newscrime, newsworld)\n",
      "403  0.01168       (newsus, newscrime, newspolitics, newsworld)\n",
      "\n",
      "[404 rows x 2 columns]\n",
      "                   antecedents                consequents  antecedent support  \\\n",
      "0                    (animals)            (lifestylebuzz)             0.03486   \n",
      "1                    (animals)                (newscrime)             0.03486   \n",
      "2                    (animals)                   (newsus)             0.03486   \n",
      "3           (autosenthusiasts)                   (newsus)             0.03210   \n",
      "4                  (autosnews)        (finance-companies)             0.03532   \n",
      "..                         ...                        ...                 ...   \n",
      "924     (newsus, newspolitics)     (newscrime, newsworld)             0.06032   \n",
      "925        (newsus, newsworld)  (newscrime, newspolitics)             0.07332   \n",
      "926  (newscrime, newspolitics)        (newsus, newsworld)             0.03154   \n",
      "927     (newscrime, newsworld)     (newsus, newspolitics)             0.04484   \n",
      "928  (newspolitics, newsworld)        (newsus, newscrime)             0.03396   \n",
      "\n",
      "     consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0               0.11798  0.01010    0.289730  2.455758  0.005987    1.241810   \n",
      "1               0.19184  0.01130    0.324154  1.689709  0.004612    1.195775   \n",
      "2               0.33340  0.01716    0.492255  1.476469  0.005538    1.312863   \n",
      "3               0.33340  0.01560    0.485981  1.457652  0.004898    1.296840   \n",
      "4               0.15718  0.01014    0.287089  1.826501  0.004588    1.182224   \n",
      "..                  ...      ...         ...       ...       ...         ...   \n",
      "924             0.04484  0.01168    0.193634  4.318331  0.008975    1.184524   \n",
      "925             0.03154  0.01168    0.159302  5.050783  0.009367    1.151971   \n",
      "926             0.07332  0.01168    0.370323  5.050783  0.009367    1.471676   \n",
      "927             0.06032  0.01168    0.260482  4.318331  0.008975    1.270665   \n",
      "928             0.09392  0.01168    0.343934  3.661989  0.008490    1.381081   \n",
      "\n",
      "     zhangs_metric  \n",
      "0         0.614205  \n",
      "1         0.422925  \n",
      "2         0.334364  \n",
      "3         0.324378  \n",
      "4         0.469073  \n",
      "..             ...  \n",
      "924       0.817756  \n",
      "925       0.865467  \n",
      "926       0.828130  \n",
      "927       0.804503  \n",
      "928       0.752479  \n",
      "\n",
      "[929 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# 进行频繁模式挖掘：同类别新闻共同出现的模式\n",
    "\n",
    "# 将 clicked_news 列中的列表转换为 one-hot 编码格式\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(clicked_df['clicked_news'].tolist()).transform(clicked_df['clicked_news'].tolist())\n",
    "df_one_hot = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# 使用 apriori 算法找出频繁项集\n",
    "frequent_itemsets = apriori(df_one_hot, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# 使用 association_rules 找出关联规则\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "# 打印频繁项集和关联规则\n",
    "print(frequent_itemsets)\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
